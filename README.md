Sign Language Recognition using Python and CNN

Recognizes hand gestures representing Aâ€“Z alphabets and 0â€“9 numbers from static images using a Convolutional Neural Network (CNN) model built in Python with TensorFlow/Keras.

ðŸ“Œ Project Overview

This project aims to assist communication for individuals with speech and hearing impairments by recognizing static hand gestures of sign language. It classifies 36 unique hand signs (Aâ€“Z + 0â€“9) using a trained deep learning model.

ðŸŽ¯ Objectives

Recognize static sign language gestures using computer vision.

Train a CNN model to classify 36 alphanumeric signs with high accuracy.

Build a scalable and modular pipeline for real-time integration in future.

ðŸ§  Technologies Used

Language: Python

Libraries: TensorFlow, Keras, OpenCV, NumPy, Pandas, Matplotlib

Model: Convolutional Neural Network (CNN)

Dataset

This project uses the ASL Dataset provided by Ayuraj on Kaggle:

ðŸ“Ž https://www.kaggle.com/datasets/ayuraj/asl-dataset


